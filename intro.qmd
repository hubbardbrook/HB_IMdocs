
# Data Management Plan

This chapter is based on the most recent Data Management Plan (DMP) developed for the 2022 LTER site renewal proposal. Subsequent chapters expand on each element and reflect recent accomplishments and detailed instructions on the various workflows used in the HBR Information Management environment.
Also available is the full [2022 HBR DMP](2022_HBRSupplementalDoc_DMP-20220317.pdf) as originally submitted.


## History of IM at the Hubbard Brook Experimental Forest {#history-of-im-at-the-hubbard-brook-experimental-forest}

The Hubbard Brook Experimental Forest (HBEF; USDA Forest Service) was established in 1955 and became an NSF-funded Long Term Ecological Research Site (HBR) in 1988. Information management has been an important component at Hubbard Brook from its inception. Data and documents from 1955 onward have been stored and protected, and although most of these early items consist of physical assets (paper charts, photographic slides, field notes, handwritten data, publications, etc), much of this material has been converted to digital format, with original copies in fireproof storage at the HBEF Pierce Lab and at the Northern Research Station in Durham, NH.

The establishment of the LTER-HBR occurred at a time of rapidly changing technology; desktop computers and email were new, and the internet as we know it was still several years away. The Hubbard Brook community fully embraced these emerging technological resources, and established access to data with the 'Source of the Brook', a public access dial-up electronic bulletin board, which allowed easy retrieval of many data sets from the HBR (1990). From a dialup bulletin board and gopher server in the early 1990s, to the World Wide Web in the late 1990s, HBR's latest technology advances in publicly sharing data and resources has seen a migration of the website to WordPress, a data catalog built on dynamic access to content in the Environmental Data Initiative repository (EDI), bibliography management in Zotero, to name a few...

Until 2012, Information management for HBR was provided through the Forest Service, with John Campbell filling this role from 1997-2012. During this time, the LTER network adopted EML (Ecological Metadata Language) as a metadata standard, and HBR was an early adopter of this standard. In 2003-4 the first EML-based data packages were prepared for HBR with online download access and formatted browser display of metadata.

Funding for the HBR Information Management position was provided in the 2010 renewal of LTER-HBR funding (HBR5), and the position was filled in mid-2012 by Mary Martin (Earth Systems Research Center, University of New Hampshire, Durham, NH).

## Governance {#governance}

Information management at the Hubbard Brook Ecosystem Study (HBES) is guided by the Information Oversight Committee (IOC), which meets on an ad hoc basis with virtual IOC meetings scheduled accordingly.

## Research Approval Committee {#research-approval-committee}

A Research Approval Committee (RAC) has been established to assist the Forest Service and broader HBES community in making decisions regarding what research studies will be allowed. In making its recommendation, the RAC considers a number of factors related to: (1) the relationship of the proposed project to the overall Hubbard Brook Ecosystem Study (how does this project fit into the overall study; why is it important for this research to occur at the Hubbard Brook Experimental Forest, as opposed to some other site); (2) the scientific merit of the proposed research; (3) the integrity of the site (e.g. how will this research impact the Forest or other ongoing research projects); and (4) the extent to which the proposed research compromises or enhances ongoing efforts. The RAC's critical review of proposed research at Hubbard Brook helps ensure that the scientific value of the Hubbard Brook Experimental Forest is maintained for the future.

Proposal submissions to the RAC are made through JotForm webforms on <https://hubbardbrook.org/research/research-proposal-submission>, and are currently being used to develop a project-level database to support the RAC review process and IM tracking of data collections at Hubbard Brook. Researchers approved by the RAC are encouraged to submit data to be included in the Hubbard Brook Data Catalog, regardless of funding source.

# Personnel {#personnel}

Hubbard Brook LTER Information management transitioned from the Forest Service to the HBR LTER grant in the HBR-V funding cycle (2010-2016). The Information Manager is based at the Earth System Research Center (ESRC), University of New Hampshire (UNH), and funded through a subcontract between the Cary Institute of Ecosystem Studies and UNH.

Information Management resources (software, hardware, and personnel) from the USDA Forest Service Northern Research station contribute substantially to the overall data holdings of the HBR. These include the collection, quality control, and development of core hydrological, meteorological, and water chemistry datasets upon which much of the HBR research relies.

See also IT resources for as-needed project support (Section 4) and Appendix 1 for a description of as-needed support from the ESRC *Laboratory for Remote Sensing and Spatial Analysis.*

# Data Packages {#data-packages}

## Overview {#overview}

HBR data packages are prepared for submission to the Environmental Data Initiative (EDI), following best practices developed over 4 decades by the LTER Information Management community (<https://ediorg.github.io/data-package-best-practices/eml-best-practices.html>). These best practices, and the efforts of the EDI, ensure that data are Findable, Accessible, Interoperable, and Reusable, following the principles of the [FAIR](https://www.go-fair.org/go-fair-initiative) initiative. The EDI serves as the primary repository for HBR data, and details about the operation of EDI can be found at [https://edirepository.org](https://edirepository.org/).

## Data Holdings {#data-holdings}

The HBR data catalog has had a strong emphasis on long-term datasets and data from the major watershed experiments. Many of these data pre-date the establishment of LTER-HBR, and are now available as a result of a 60+ year culture of robust data curation and sharing. More than 20 HBR data packages have been collected over a period of 50 or more years, with another 30 covering a timespan of more than 20 years. Through close coordination with the Research Approval Committee, the Hubbard Brook Committee of Scientists, and project administration, HBR-IM is able to identify datasets that can be incorporated into our data catalog. Graduate students working at Hubbard Brook are also surveyed periodically to identify forthcoming datasets and they are also trained in the EDI data publication workflow.

## Metadata Standards {#metadata-standards}

All HBR data packages are prepared for submission through the development of metadata in the Ecological Metadata Language standard (EML; <https://eml.ecoinformatics.org/eml-ecological-metadata-language>). Basic EML content includes: title, abstract, personnel, contacts, publication date, spatial and temporal coverages, keywords (consistent with LTER controlled vocabulary), project funding, publisher, data access and use policies, and detailed attribute-level metadata. Data download and use is facilitated through the fully described attribute metadata (column names, definitions, units, missing values, and coding). The highest level of EML completion is achieved through the EDI congruency checker with informational, warning, and error messages that provide feedback to HBR-IM on additional steps that can (or must) be taken to submit to the repository. These congruency checks read both metadata and data, testing a minimum of 40 conditions that can be addressed to insure that data packages are are fully capable of integration with other data, and fully operational in higher level workflows and automated data processing.

In 2019, LTER sites began using EML2.2. EML2.2 provides the structure to accommodate a number of advanced metadata elements. Of note, is the ability to annotate data packages at the data package, entity, and attribute level, by linking to persistent identifiers in ontologies, such as those found at <https://bioportal.bioontology.org/ontologies> and elsewhere. As the annotation elements in EML2.2 become populated, both the discoverability of datasets, and the ability to use datasets in synthesis efforts will be enhanced. HBR-IM has been a member of both the EDI Semantics Working Group (formed in January 2019), and the EDI/LTER Units Working group (2023-present), which have a goal of developing best practices and training on the use of the new EML2.2 annotation elements. The Units Working Group is responsive to recommendations from the LTER 40-year review on facilitating synthesis efforts. This has been accomplished by establishing a relationship with the QUDT ontology (<https://qudt.org),> developing code to map ad hoc units to this ontology, and preparing a manuscript on this effort for publication.

## Data Package Development {#data-package-development}

HBR IM has fully adopted the EDI ezEML application for data package development. This cloud-based application was developed by EDI and users are supported by the EDI team and ezEML developer. This application continues to be developed to support emerging LTER/EDI data requirements. Within this system, HBR can store templates for access and re-use of common metadata elements (people, taxonomy, geographic coverage, funding, etc). EzEML also supports a 'collaboration' mode, where IM and data creators can work together to complete the full metadata documentation necessary for the repository.

A separate chapter describes the data package development workflow in detail: [HBR Data Package Development](DataPackageWorkflow.qmd).

## Data Quality Control

The HBR research community is widely dispersed among different institutions and laboratories, and data quality control is implemented primarily by the individual researcher. All data packages include methods, wherein detailed data QC protocols can be documented. The HBR-IM works with research teams to document quality control in the data package metadata as appropriate. This may range from descriptions directly in EML, PDF files uploaded with data packages, or cross referencing to details on data QC available elsewhere. IM provides the data submitter with feedback on a number of QC checks that are implemented during the data package development workflow. These include value ranges for data table attributes, coding consistency, and additional issues that are flagged within the ezEML environment and the EDI congruency checker (the final checks during repository upload).

## Access Policy {#access-policy}

The HBR data policy follows that of the LTER Data Access Policy, as updated in 2017. (<https://lternet.edu/data-access-policy>/; Creative Commons license - Attribution - CC BY; <https://creativecommons.org/licenses/by/4.0/>). All pre-existing HBR data packages have been revised to include this new policy, and the policy is linked on the hubbardbrook.org information management page. The policy reads as follows:

> *This information is released under the Creative Commons license - Attribution - CC BY (<https://creativecommons.org/licenses/by/4.0/>). The consumer of these data ("Data User" herein) is required to cite it appropriately in any publication that results from its use. The Data User should realize that these data may be actively used by others for ongoing research and that coordination may be necessary to prevent duplicate publication. The Data User is urged to contact the authors of these data if any questions about methodology or results occur. Where appropriate, the Data User is encouraged to consider collaboration or co-authorship with the authors. The Data User should realize that misinterpretation of data may occur if used out of context of the original study.*
>
> *While substantial efforts are made to ensure the accuracy of data and associated documentation, complete accuracy of data sets cannot be guaranteed. All data are made available "as is." The Data User should be aware, however, that data are updated periodically and it is the responsibility of the Data User to check for new versions of the data. The data authors and the repository where these data were obtained shall not be liable for damages resulting from any use or misinterpretation of the data.*

## Data Access {#data-access}

The complete inventory of Hubbard Brook data can be browsed, filtered, and searched on the HBR website <https://hubbardbrook.org/d/hubbard-brook-data-catalog>. Data are also discoverable through both the EDI data portal ([https://portal.edirepository.org](https://portal.edirepository.org/)), through DataONE ([https://search.dataone.org](https://search.dataone.org/)), google dataset search (<https://datasetsearch.research.google.com/>), and through DataCite ([https://datacite.org](https://datacite.org/)), the entity providing dataset DOIs to EDI. A separate stand-alone document is generated as needed (for proposals and reviews), and describes all HBR data packages in the EDI (and other) repository -- ***Hubbard Brook Data Catalog Inventory***.



Also see ESRC Computer Resources appendix 1.

Table 1 outlines software in use by HBR-IM to manage data package development and the Hubbard Brook website.

Table 1. Features of HBR Information Management System

| **Feature**                                                    | **Details, software, resources**                                         |
|-------------------------------------|-----------------------------------|
| Website: [https://hubbardbrook.org](https://hubbardbrook.org/) | WordPress, html, css, php, xslt, javascript, apache, piwigo              |
| Bibliography                                                   | Zotero, Zotpress wordpress plugin                                        |
| Data Catalog                                                   | EDI data repository, local WordPress gateway to EDI HBR data, EDIutils R |
| Metadata                                                       | ezEML, PostgreSQL, EML R package, EML2.1                                 |
| Computer Hardware                                              | Dell Poweredge R510, desktop and laptop linux systems.                   |
| Backup                                                         | BackupPC, rsnapshot, daily, weekly and monthly backups, on and off-site  |
| Data management                                                | R, LibreOffice, QGIS, MySQL, PostgreSQL, git                             |

## Account access

-   IM desktop and server
-   UNH HB sharepoint
-   zotero
-   Databases
-   piwigo
-   EDI/ezEML

# Website {#website}

The HBR website ([https://hubbardbrook.org](https://hubbardbrook.org/)) is the primary means by which HBR information is disseminated, with additional non-digital data (charts, maps, photographs) made available upon request. HBR completed a website migration from html/php files to a content management system (CMS; Drupal) in 2017. In 2022 the website was further migrated to WordPress. With cloud-based WordPress hosting, it becomes simpler to transfer website management to a different IM and/or institution. Website content is managed by the HBR IM and the Hubbard Brook Research Foundation. The website provides access to data, publications, personnel pages, education and outreach material, and a photo gallery. A recent website content addition is the Hubbard Brook Research Synthesis -- an online 'book' consisting of 19 chapters to date, covering a wide range of long-term research. With content editors assigned to each chapter, this is meant to be a series of dynamic pages, which reflect the full history of Hubbard Brook research in each topic area (<https://hubbardbrook.org/online-book>). Chapters in the online book contain numerous data figures, many of which have been restructured to read data directly from the most recent data revisions in the EDI repository.

See ***Hubbard Brook Ecosystem Study Website Management Guide*** for website configuration, access to servers and filesystems, recommended practices for site content, etc.

# Sample Archive {#sample-archive}

## Samples {#samples}

In 1990, an archive facility was built at the Hubbard Brook Experimental Forest to store samples permanently so that they will be available for future research. The 1860 sq. ft. building consists of two rooms: a larger unheated room (30 x 46 ft.) and a smaller room (16 x 30 ft.) heated to just above freezing in the winter. The larger room is uninsulated and is subject to large variations in temperature and humidity; the most scientifically valuable samples are stored in the smaller, insulated, heated room.

The archive building now houses approximately 70,000 samples of soil, water, plant tissue, and other materials. Samples are preserved, barcoded, and cataloged with accompanying metadata in a database. This database of bar-coded samples is searchable online at <https://data.hubbardbrook.org/samples/>. In 2024, both the underlying collection and sample database and the search interface are being restructured. This effort is resulting in improved collection organization and more detailed sample-level metadata.

Requests for reanalysis of archived samples (e.g. isotopic analyses, heavy metals, etc.) are received periodically, and have resulted in a number of publications.

A Sample Archive Committee (SAC) was formed in 2013 to address storage space, future direction, priority for continued bar-coding, etc.

## Sample Archive Subsampling Policy {#sample-archive-subsampling-policy}

HBR shares these archived samples with scientists upon request. As stewards of these samples, our highest priorities are:

1.  to maintain the chemical integrity of these samples;

2.  to document the use of these samples, and any resulting changes;

3.  inform principal investigators of interest in using them;

4.  to acknowledge the appropriate funding sources for their original collection.

Details on the subsampling of archived material can be found on the sample request form:

<https://hubbardbrook.org/sites/default/files/documents/subsampling_request.pdf>

## Directions for Sample Submission {#directions-for-sample-submission}

Requirements for acceptance of samples into the archive:

1.  Adequate documentation must accompany physical samples.

2.  Samples are stored in either an unheated large room or a smaller room that is heated to just above freezing. The contributing scientist is responsible for deciding that these conditions are suitable for his/her samples.

3.  Soil samples must be air or oven-dried and stored in plastic or glass bottles with screw caps to ensure a tight seal. Cardboard is not permitted.

4.  Vegetation samples should be dried, ground and stored in clear plastic or glass containers.

5.  Water samples must be stored in plastic bottles and will be accepted either treated, or not. If treated, the investigator must specify the type and concentration used.

6.  All tree logs, cookies and cores should be air-dried and can be stored in cardboard boxes or arranged in a manner that will allow for air to flow between individual samples. Tree cores should be mounted or stored in straws.

7.  Samples that are considered toxic may be rejected. The data management committee may confer with the SAC about important, but toxic samples requiring storage.

# Bibliography {#bibliography}

The current bibliography for Hubbard Brook includes Books, Journal Articles, Conference Presentations, and Theses; currently with more than 2400 entries.

Citations are managed locally in Zotero ([https://zotero.org](https://zotero.org/)). This open source bibliography management software allows for export to standard reference management exchange formats, harvests citation information easily through a browser, and provides cite-as-you-write support for MSWord and Open/LibreOffice.

The Zotero bibliography is mirrored to the cloud, and publications are accessed through a link to this service. The WordPress zotpress plugin provides the functionality of linking each HB researcher's profile page to their Hubbard Brook publications.

The Hubbard Brook bibliography is also mirrored to the LTER Network Communication Office (NCO) central LTER bibliographic database.

# Appendix 1. ESRC/UNH Computing Facilities {#appendix-1.-esrcunh-computing-facilities}

The Earth Systems Research Center's (ESRC) Science Computing Facility (SCF) has a wide range of computer servers, printers, plotters, archiving systems, software, data archives, and web based data distribution systems that are integrated using several internal networks and connected to the outside world through a high speed pipe. The overall SCF administration is provided by the Research Computing Center (RCC) located in the Institute for the Study of Earth, Oceans and Space (EOS). Scientific data processing and analysis support is distributed throughout workgroups within the center with additional centralized expertise provided by ESRC's Laboratory for Remote Sensing and Spatial Analysis. RCC's Lenharth Data Center was upgraded in September 2011. This upgrade brought in new APC UPS units, energy efficient in-rack cooling systems, and monitoring hardware to provide more space and capability for future growth. Within this proposal, we take advantage of this existing computer infrastructure, to meet our anticipated computational needs.

The main ESRC servers consist of high-end, multi-processor computing systems manufactured by Dell. The Dell systems run Linux and are used for CPU intensive jobs, parallel modeling, and storage. Backups and archives are done using BackupPC a disk-to-disk based system. Most of the main servers share a gigabit (Gb) switch with the archive/backup system for high-speed communications. All of this equipment is kept within a physically secured, humidity and temperature controlled data center complete with closed circuit video surveillance and a remotely monitored security alarm system. Final data and image products are produced from several ink-jet plotters and laser printers within the department. Additionally, several CD/DVD writers are used for data distribution.

EOS includes a CRAY XE6m-200 with 132 nodes, over 4000 processors and 160Tb of storage. In addition, our infrastructure has been strategically upgraded to provide gigabit networking to desktops.

Individual scientists and research groups have additional computing resources at their disposal. These include dedicated servers, individual workstations, and various peripheral devices. The group servers and individual workstations include: Linux servers and workstations, Windows workstations, Apple Macintosh desktop and laptop computers. All servers, user systems and networked peripheral devices are accessible within EOS through a gigabit ethernet network. Wireless networking is available throughout the building, including access to EduRoam. These systems also have access to both Internet 1 and Internet 2.

ESRC currently houses a 65TB+ geographically referenced data archive used for spatial data processing and analysis. This archive stored on RAID5 data disks served by a series of data servers, houses global, regional and local, Landsat, MODIS, IKONOS, Hyperion, ASTER, and SPOT satellite imagery, land cover classified products, vegetation and other indexes (EVI, LSWI, NDSI, NDVI, NDWI, LAI), aerial photography and GIS vector data layers for use by all projects within the department. Portions of these data, processed data products, and project results archive are disseminated and distributed through several dozen regularly updated and maintained ESRC operated websites. These websites are served through a variety of web servers running Apache web server software supported by other applications and libraries such as Tomcat, Web Mapping Server (WMS), OpenLayers and other geographically enhanced libraries such as GDAL, PROJ4, and GCTP.

ESRC also leverages the center's Laboratory for Remote Sensing and Spatial Analysis, a spatial information processing, analysis and distribution research laboratory. This laboratory provides geographic information system (GIS), Web Mapping, spatial data archiving, data distribution, remote sensing, image processing, cartography, large format printing and scanning support to several ESRC and EOS research projects. Staffed by professional geo-spatial information technicians, computer programmers, and graduate and undergraduate university students, the laboratory houses a multiple seat Linux, PC, and Mac OS computer cluster supplied with a variety of open source Remote Sensing, GIS, web mapping, image processing and cartography software and ESRI ArcGIS, Leica ERDAS Imagine, and IDL/ENVI, commercial site, block, and individually licensed GIS and Image processing software.
